{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JzQ1NCkJ9oNW",
        "2mzuUaw-FrvF",
        "rVo1PHTRK02x",
        "xvfRf5blCP05",
        "v9SIeajzDm82",
        "1jK186WoDI94",
        "dlRL1MwrF9Y2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQ1NCkJ9oNW"
      },
      "source": [
        "# **Conexão com o Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6Hg27Ck7TUO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# 1 - Dê a permissão\n",
        "# 2 - Copie e cole o código gerado\n",
        "# 3 - Coloque o arquivo dataZ24.mat no diretório raiz do drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mzuUaw-FrvF"
      },
      "source": [
        "# **Importação de bibliotecas tradicionais**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDw0qUIVFueK"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVo1PHTRK02x"
      },
      "source": [
        "# **Carregamento e visualização dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CbM7gBO97uF"
      },
      "source": [
        "#Carregar os dados\n",
        "X = sio.loadmat('/content/drive/My Drive/dataZ24.mat')['data']\n",
        "print('Dimensões da base de dados: ' + str(np.shape(X)))\n",
        "X_treino = X[0:198,:]\n",
        "print('Dimensões do conjunto de treino: ' + str(np.shape(X_treino)))\n",
        "X_teste = X[0:235,:]\n",
        "print('Dimensões do conjunto de teste: ' + str(np.shape(X_teste)))\n",
        "n_normal = X_treino.shape[0]\n",
        "print(f'Quantidade de dados da condição normal: {n_normal}')\n",
        "n_total = X_teste.shape[0]\n",
        "print(f'Quantidade de dados das condições normal e anormal: {n_total}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmGvSy8r-akx"
      },
      "source": [
        "ax = np.linspace(1, n_total, n_total)\n",
        "plt.plot(ax[0:n_normal], X_treino[:,0], 'b^', label='Normal')\n",
        "plt.plot(ax[0:n_normal], X_treino[:,1], 'b^')\n",
        "plt.plot(ax[n_normal:n_total], X_teste[198:,0], 'r^', label='Anormal')\n",
        "plt.plot(ax[n_normal:n_total], X_teste[198:,1], 'r^')\n",
        "plt.xlabel('Número de observações')\n",
        "plt.ylabel('Frequência (Hz)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvfRf5blCP05"
      },
      "source": [
        "# **Funções auxiliares**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bcPt6ICCSol"
      },
      "source": [
        "def est_threshold(scores, level=0.95):\n",
        "\n",
        "    aux = np.sort(scores,axis=0)\n",
        "\n",
        "    thr = aux[round(aux.shape[0]*level)-1]\n",
        "\n",
        "    return thr\n",
        "\n",
        "\n",
        "def get_errors(scores, flag, thr):\n",
        "\n",
        "    n = scores.shape[0]\n",
        "    nb = np.sum(flag == 0)\n",
        "\n",
        "    class_state = np.zeros((n, 1))\n",
        "\n",
        "    class_state[scores > thr] = 1\n",
        "\n",
        "    num_errors_type1 = np.sum((class_state == 1) & (flag == 0))\n",
        "\n",
        "    num_errors_type2 = np.sum((class_state == 0) & (flag == 1))\n",
        "\n",
        "    perc_errors_type1 = num_errors_type1/nb*100\n",
        "    perc_errors_type2 = num_errors_type2/(n-nb)*100\n",
        "\n",
        "    return num_errors_type1, num_errors_type2, perc_errors_type1, perc_errors_type2\n",
        "\n",
        "def get_flag_test(n, nb):\n",
        "\n",
        "    flag_test = np.zeros((n, 1))\n",
        "\n",
        "    flag_test[nb:] = 1\n",
        "\n",
        "    return flag_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9SIeajzDm82"
      },
      "source": [
        "# **Definição das flags (rótulos) dos dados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbTSaB8tDtfm"
      },
      "source": [
        "flag_test = get_flag_test(n_total,n_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jK186WoDI94"
      },
      "source": [
        "# **Algoritmo Mahalanobis Squared distance (MSD)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF2Q8dbuDR3f"
      },
      "source": [
        "def learn_mahalanobis(train_data):\n",
        "\n",
        "    data_mean = np.mean(train_data, axis=0)\n",
        "    data_cov = np.cov(train_data.T)\n",
        "\n",
        "    model = {'data_mean': np.array([data_mean]),\n",
        "             'data_cov': data_cov}\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def score_mahalanobis(test_data, model):\n",
        "\n",
        "    n = test_data.shape[0]\n",
        "    data_mean = model['data_mean']\n",
        "    data_cov = model['data_cov']\n",
        "\n",
        "    scores = np.zeros((n,1))\n",
        "\n",
        "    for i in range(0, n):\n",
        "\n",
        "        scores[i, :] = np.dot(test_data[i,:]-data_mean,np.dot(np.linalg.pinv(data_cov), (test_data[i,:]-data_mean).T))\n",
        "\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0j8GPUGWDUoh"
      },
      "source": [
        "model = learn_mahalanobis(X_treino)\n",
        "scores = score_mahalanobis(X_teste,model)\n",
        "scores_thr = score_mahalanobis(X_treino,model)\n",
        "thr = est_threshold(scores_thr)\n",
        "\n",
        "num_err_t1, num_err_t2, per_err_t1, per_err_t2 = get_errors(scores, flag_test, thr)\n",
        "print(f'Erros Tipo 1 (falso-positivo): {num_err_t1}')\n",
        "print(f'Erros Tipo 2 (falso-negativo): {num_err_t2}')\n",
        "print(f'Porcentagem de erros Tipo 1: {per_err_t1:.2f}')\n",
        "print(f'Porcentagem de erros Tipo 2: {per_err_t2:.2f}')\n",
        "\n",
        "scores = np.log(scores) #esta linha so precisa para o MSD\n",
        "thr = np.log(thr) #esta linha so precisa para o MSD\n",
        "ix_out = scores > thr\n",
        "ax = np.linspace(1, n_total, n_total)\n",
        "plt.plot(ax[np.squeeze(ix_out)], scores[ix_out], 'yo', label='Outlier', markersize=12)\n",
        "plt.plot(ax[0:n_normal], scores[0:n_normal], 'b^', label='Normal')\n",
        "plt.plot(ax[n_normal:n_total], scores[n_normal:n_total], 'r^', label='Anormal')\n",
        "plt.plot(ax,thr*np.ones(ax.shape), 'k--', label='Limiar')\n",
        "plt.xlabel('Número de observações')\n",
        "plt.ylabel('Indicador de anomalia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlRL1MwrF9Y2"
      },
      "source": [
        "# **Algoritmo k-means**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6GkfSDPGC0K"
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def learn_KM(train_data, nc):\n",
        "\n",
        "    km = KMeans(n_clusters=nc).fit(train_data)\n",
        "    labels = km.labels_\n",
        "    cluster_centers_ = km.cluster_centers_\n",
        "\n",
        "    n_clusters = km.n_clusters\n",
        "\n",
        "    labelsClusterCenters = km.predict(km.cluster_centers_)\n",
        "\n",
        "    print(\"Númbero de clusters estimados: {}\".format(n_clusters))\n",
        "\n",
        "    plt.scatter(train_data[:, 0], train_data[:, 1], s=10, c=labels)\n",
        "    plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s=100, c=labelsClusterCenters)\n",
        "    plt.show()\n",
        "\n",
        "    model = {'n_clusters':n_clusters,'cluster_centers':cluster_centers_,'labels':labels}\n",
        "\n",
        "    return model\n",
        "\n",
        "def score_KM(test_data, model):\n",
        "\n",
        "    n = test_data.shape[0]\n",
        "    n_clusters = model['n_clusters']\n",
        "    cluster_centers = model['cluster_centers']\n",
        "\n",
        "    scores_aux = np.zeros((n, n_clusters))\n",
        "\n",
        "    for i in range(0, n_clusters):\n",
        "\n",
        "        residuals = test_data - cluster_centers[i, :]\n",
        "\n",
        "        scores_aux[:, i] = np.squeeze(np.linalg.norm(residuals, axis=1, keepdims=True))\n",
        "\n",
        "    scores = np.min(scores_aux, axis=1, keepdims=True)\n",
        "\n",
        "    return scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVVdBmm9GPGZ"
      },
      "source": [
        "model = learn_KM(X_treino, nc=3)\n",
        "scores = score_KM(X_teste,model)\n",
        "scores_thr = score_KM(X_treino,model)\n",
        "thr = est_threshold(scores_thr)\n",
        "\n",
        "num_err_t1, num_err_t2, per_err_t1, per_err_t2 = get_errors(scores, flag_test, thr)\n",
        "print(f'Erros Tipo 1 (falso-positivo): {num_err_t1}')\n",
        "print(f'Erros Tipo 2 (falso-negativo): {num_err_t2}')\n",
        "print(f'Porcentagem de erros Tipo 1: {per_err_t1:.2f}')\n",
        "print(f'Porcentagem de erros Tipo 2: {per_err_t2:.2f}')\n",
        "\n",
        "ix_out = scores > thr\n",
        "ax = np.linspace(1, n_total, n_total)\n",
        "plt.plot(ax[np.squeeze(ix_out)], scores[ix_out], 'yo', label='Outlier', markersize=12)\n",
        "plt.plot(ax[0:n_normal], scores[0:n_normal], 'b^', label='Normal')\n",
        "plt.plot(ax[n_normal:n_total], scores[n_normal:n_total], 'r^', label='Anormal')\n",
        "plt.plot(ax,thr*np.ones(ax.shape), 'k--', label='Limiar')\n",
        "plt.xlabel('Número de observações')\n",
        "plt.ylabel('Indicador de anomalia')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}